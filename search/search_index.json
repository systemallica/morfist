{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"morfist: mixed-output-rf","text":"<p>Multi-target Random Forest implementation that can mix both classification and regression tasks.</p> <p>Morfist implements the Random Forest algorithm (Breiman, 2001) with support for mixed-task multi-task learning, i.e., it is possible to train the model on any number of classification tasks and regression tasks, simultaneously. Morfist's mixed multi-task learning implementation follows that proposed by Linusson (2013). </p> <ul> <li>Breiman, L. (2001). Random forests. Machine learning, 45(1), 5-32.</li> <li>Linusson, H. (2013). Multi-output random forests.</li> </ul>"},{"location":"#installation","title":"Installation","text":"<p>With pip: <pre><code>pip install decision-tree-morfist\n</code></pre> With conda: <pre><code>conda install -c systemallica decision-tree-morfist\n</code></pre></p>"},{"location":"#usage","title":"Usage","text":""},{"location":"#initialising-the-model","title":"Initialising the model","text":"<ul> <li>Similarly to a scikit-learn RandomForestClassifier, a MixedRandomForest can be initialised in this way: <pre><code>from morfist import MixedRandomForest\n\nmrf = MixedRandomForest(\n    n_estimators=n_trees,\n    min_samples_leaf=1,\n    classification_targets=[0]\n)\n</code></pre></li> <li> <p>The available parameters are:</p> <ul> <li> <p>n_estimators(int): the number of trees in the forest. Optional. Default value: 10.</p> </li> <li> <p>max_features(int | float | str): the number of features to consider when looking for the best split. Optional. Default value: 'sqrt'.</p> <ul> <li>If int, then consider max_features features at each split.</li> <li>If float, then max_features is a fraction and int(max_features * n_features) features are considered at each split.</li> <li>If \u201csqrt\u201d, then max_features=sqrt(n_features) (same as \u201cauto\u201d).</li> <li>If \u201clog2\u201d, then max_features=log2(n_features).</li> <li>If None, then max_features=n_features.</li> </ul> <p>Note: the search for a split does not stop until at least one valid partition of the node samples is found, even if it requires to effectively inspect more than max_features features.</p> </li> <li> <p>min_samples_leaf(int): the minimum number of samples required to be at a leaf node. Optional. Default value: 5.</p> <p>Note: A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression.</p> </li> <li> <p>choose_split(str): method used to find the best split. Optional. Default value: 'mean'.</p> <p>By default, the mean information gain will be used.</p> <ul> <li>Possible values:<ul> <li>'mean': the mean information gain is used.</li> <li>'max': the maximum information gain is used.</li> <li>'random': one of the predictive tasks is selected at random, and its individual information gain is chosen as the information gain for the split.</li> </ul> </li> </ul> </li> <li> <p>classification_targets(int[]): features that are part of the classification task. Optional. Default value: None.</p> <p>If no classification_targets are specified, the random forest will treat all variables as regression variables.</p> </li> </ul> </li> </ul>"},{"location":"#training-the-model","title":"Training the model","text":"<ul> <li>Once the model is initialised, it can be fitted like this:     <pre><code>mrf.fit(X, y)\n</code></pre>     Where X are the training examples and Y are their respective labels(if they are categorical) or values(if they are numerical)</li> </ul>"},{"location":"#prediction","title":"Prediction","text":"<ul> <li>The model can be now used to predict new instances.<ul> <li>Class/value: <pre><code>mrf.predict(x)\n</code></pre></li> <li>Probability: <pre><code>mrf.predict_proba(x)\n</code></pre></li> </ul> </li> </ul>"},{"location":"#runbuild-locally","title":"Run/Build locally","text":"<p>To run the project, you need Poetry. Once installed:</p> <ol> <li>Clone the repository.</li> <li>Run <code>poetry install</code>.</li> <li>The development environment is ready. You can test it by running <code>pytest</code>.</li> </ol>"}]}